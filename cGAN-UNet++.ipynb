{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b06cc19a",
   "metadata": {},
   "source": [
    "## UNet++ cGAN that outputs RGB images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60b1a8ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import scipy\n",
    "from glob import glob\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage import transform\n",
    "from __future__ import print_function, division\n",
    "import tensorflow as tf\n",
    "from keras.layers import Input, Dense, Reshape, Flatten, Dropout, Concatenate, concatenate\n",
    "from keras.layers import BatchNormalization, Activation, ZeroPadding2D, MaxPooling2D, Conv2DTranspose\n",
    "from keras.layers import LeakyReLU\n",
    "from keras.layers.convolutional import UpSampling2D, Conv2D\n",
    "from keras.models import Sequential, Model\n",
    "from keras.optimizers import Adam\n",
    "import datetime\n",
    "import sys\n",
    "import os\n",
    "from imageio import imread\n",
    "from PIL import Image\n",
    "import pickle\n",
    "from skimage.metrics import structural_similarity as ssim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f5cc74db",
   "metadata": {},
   "outputs": [],
   "source": [
    "#GPU config\n",
    "import tensorflow as tf\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "\n",
    "config = tf.compat.v1.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "sess = tf.compat.v1.Session(config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dbc29bed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(batch_size=1, is_val = False):\n",
    "       \n",
    "        path_SAR = glob('Datasets/v_2/agri/s1/*')\n",
    "        \n",
    "        batch_images = np.random.choice(path_SAR, size=batch_size)\n",
    "        img_res=(256,256)\n",
    "        imgs_A = []\n",
    "        imgs_B = []\n",
    "        for img_path in batch_images:\n",
    "            img_B = imread(img_path)\n",
    "            img_A = imread(img_path.replace('/s1', '/s2').replace(\"_s1_\",\"_s2_\"))\n",
    "    \n",
    "            # decreasing the resolution \n",
    "            img_A = transform.resize(img_A, img_res)  #Ground Truth image\n",
    "            img_B = transform.resize(img_B, img_res)  #Input image\n",
    "\n",
    "            # If training => do random flip , this is a trick to avoid overfitting \n",
    "            if not is_val and np.random.random() < 0.5:\n",
    "                img_A = np.fliplr(img_A)\n",
    "                img_B = np.fliplr(img_B)\n",
    "\n",
    "            imgs_A.append(img_A)\n",
    "            imgs_B.append(img_B)\n",
    "            \n",
    "        \n",
    "        imgs_A = np.array(imgs_A)/127.5 - 1.  #normalizing the images\n",
    "        imgs_B = np.array(imgs_B)/127.5 - 1.\n",
    "\n",
    "        return imgs_A, imgs_B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8292c66b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_batch(batch_size=1, is_val=False):\n",
    "        \n",
    "        path_SAR = glob('Datasets/v_2/agri/s1/*')\n",
    "        \n",
    "        n_batches=batch_size\n",
    "        img_res=(256,256)\n",
    "        for i in range(n_batches-1):\n",
    "            batch = path_SAR[i*batch_size:(i+1)*batch_size]\n",
    "            imgs_A, imgs_B = [], []\n",
    "            for img in batch:\n",
    "                img_B = imread(img)\n",
    "                img_A = imread(img.replace('/s1', '/s2').replace(\"_s1_\",\"_s2_\"))\n",
    "                \n",
    "                img_A = transform.resize(img_A, img_res)#Ground truth image\n",
    "                img_B = transform.resize(img_B, img_res)# input image\n",
    "                \n",
    "                 # when training => do random flip , this is a trick to avoid overfitting \n",
    "                if not is_val and np.random.random() > 0.5:\n",
    "                        img_A = np.fliplr(img_A)\n",
    "                        img_B = np.fliplr(img_B)\n",
    "                \n",
    "                imgs_A.append(img_A)\n",
    "                imgs_B.append(img_B)\n",
    "            # normalizing the images \n",
    "            imgs_A = np.array(imgs_A)/127.5 - 1.\n",
    "            imgs_B = np.array(imgs_B)/127.5 - 1.\n",
    "\n",
    "            yield imgs_A, imgs_B\n",
    "\n",
    "def imread(path):\n",
    "    #open image and convert it to float32.\n",
    "    return np.array(Image.open(path).convert('RGB')).astype(np.float32)\n",
    "                            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9b77f671",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from PIL import Image\n",
    "\n",
    "# path_SAR = glob('Datasets/v_2/agri/s1/*')\n",
    "\n",
    "\n",
    "# # Open an image file\n",
    "# image = Image.open(path_SAR[1].replace('/s1', '/s2').replace(\"_s1_\",\"_s2_\"))\n",
    "\n",
    "# # Display the image\n",
    "# image.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b5ffc6d",
   "metadata": {},
   "source": [
    "### UNNet++ Architecture"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "121ad4cc",
   "metadata": {},
   "source": [
    "<img src=\"UNet++Arch.jpg\" alt=\"Alt text\" width=\"500\" height=\"300\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e4a2e461",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_generator():\n",
    "        \"\"\"U-Net++ Generator architecture shown above\"\"\"\n",
    "        \n",
    "        #nb_filter = [32,64,128,256,512]\n",
    "        nb_filter=[8, 16, 32, 64, 128] #number of filters in each layer of the architecture\n",
    "        inputs = Input(shape=img_shape)\n",
    "        \n",
    "        # X11 block\n",
    "        conv1_1 = Conv2D(nb_filter[0], (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (inputs)\n",
    "        conv1_1 = Dropout(0.5) (conv1_1)\n",
    "        conv1_1 = Conv2D(nb_filter[0], (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (conv1_1)\n",
    "        conv1_1 = Dropout(0.5) (conv1_1)\n",
    "        pool1_1 = MaxPooling2D((2, 2), strides=(2, 2)) (conv1_1)\n",
    "        \n",
    "        # X21 block\n",
    "        conv2_1 = Conv2D(nb_filter[1], (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (pool1_1)\n",
    "        conv2_1 = Dropout(0.5) (conv2_1)\n",
    "        conv2_1 = Conv2D(nb_filter[1], (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (conv2_1)\n",
    "        conv2_1 = Dropout(0.5) (conv2_1)\n",
    "        pool2_1 = MaxPooling2D((2, 2), strides=(2, 2)) (conv2_1)\n",
    "        \n",
    "        # X12 block\n",
    "        up1_2 = Conv2DTranspose(nb_filter[0], (2, 2), strides=(2, 2), name='up12', padding='same')(conv2_1)\n",
    "        conv1_2 = concatenate([up1_2, conv1_1], name='merge12', axis=3)\n",
    "        conv1_2 = Conv2D(nb_filter[0], (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (conv1_2)\n",
    "        conv1_2 = Dropout(0.5) (conv1_2)\n",
    "        conv1_2 = Conv2D(nb_filter[0], (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (conv1_2)\n",
    "        conv1_2 = Dropout(0.5) (conv1_2)\n",
    "        \n",
    "        # X31 block\n",
    "        conv3_1 = Conv2D(nb_filter[2], (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (pool2_1)\n",
    "        conv3_1 = Dropout(0.5) (conv3_1)\n",
    "        conv3_1 = Conv2D(nb_filter[2], (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (conv3_1)\n",
    "        conv3_1 = Dropout(0.5) (conv3_1)\n",
    "        pool3_1 = MaxPooling2D((2, 2), strides=(2, 2), name='pool3_1')(conv3_1)\n",
    "\n",
    "        # X22 block\n",
    "        up2_2 = Conv2DTranspose(nb_filter[1], (2, 2), strides=(2, 2), name='up22', padding='same')(conv3_1)\n",
    "        conv2_2 = concatenate([up2_2, conv2_1], name='merge22', axis=3) #x10\n",
    "        conv2_2 = Conv2D(nb_filter[1], (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (conv2_2)\n",
    "        conv2_2 = Dropout(0.5) (conv2_2)\n",
    "        conv2_2 = Conv2D(nb_filter[1], (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (conv2_2)\n",
    "        conv2_2 = Dropout(0.5) (conv2_2)\n",
    "        \n",
    "        # X13 block\n",
    "        up1_3 = Conv2DTranspose(nb_filter[0], (2, 2), strides=(2, 2), name='up13', padding='same')(conv2_2)\n",
    "        conv1_3 = concatenate([up1_3, conv1_1, conv1_2], name='merge13', axis=3)\n",
    "        conv1_3 = Conv2D(nb_filter[0], (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (conv1_3)\n",
    "        conv1_3 = Dropout(0.5) (conv1_3)\n",
    "        conv1_3 = Conv2D(nb_filter[0], (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (conv1_3)\n",
    "        conv1_3 = Dropout(0.5) (conv1_3)\n",
    "        \n",
    "        # X41 block\n",
    "        conv4_1 = Conv2D(nb_filter[3], (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (pool3_1)\n",
    "        conv4_1 = Dropout(0.5) (conv4_1)\n",
    "        conv4_1 = Conv2D(nb_filter[3], (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (conv4_1)\n",
    "        conv4_1 = Dropout(0.5) (conv4_1)\n",
    "        pool4_1 = MaxPooling2D((2, 2), strides=(2, 2), name='pool4_1')(conv4_1)\n",
    "        \n",
    "        # X32 block\n",
    "        up3_2 = Conv2DTranspose(nb_filter[2], (2, 2), strides=(2, 2), name='up32', padding='same')(conv4_1)\n",
    "        conv3_2 = concatenate([up3_2, conv3_1], name='merge32', axis=3) #x20\n",
    "        conv3_2 = Conv2D(nb_filter[2], (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (conv3_2)\n",
    "        conv3_2 = Dropout(0.5) (conv3_2)\n",
    "        conv3_2 = Conv2D(nb_filter[2], (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (conv3_2)\n",
    "        conv3_2 = Dropout(0.5) (conv3_2)\n",
    "        \n",
    "        # X23 block\n",
    "        up2_3 = Conv2DTranspose(nb_filter[1], (2, 2), strides=(2, 2), name='up23', padding='same')(conv3_2)\n",
    "        conv2_3 = concatenate([up2_3, conv2_1, conv2_2], name='merge23', axis=3)\n",
    "        conv2_3 = Conv2D(nb_filter[1], (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (conv2_3)\n",
    "        conv2_3 = Dropout(0.5) (conv2_3)\n",
    "        conv2_3 = Conv2D(nb_filter[1], (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (conv2_3)\n",
    "        conv2_3 = Dropout(0.5) (conv2_3)\n",
    "        \n",
    "        # X14 block\n",
    "        up1_4 = Conv2DTranspose(nb_filter[0], (2, 2), strides=(2, 2), name='up14', padding='same')(conv2_3)\n",
    "        conv1_4 = concatenate([up1_4, conv1_1, conv1_2, conv1_3], name='merge14', axis=3)\n",
    "        conv1_4 = Conv2D(nb_filter[0], (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (conv1_4)\n",
    "        conv1_4 = Dropout(0.5) (conv1_4)\n",
    "        conv1_4 = Conv2D(nb_filter[0], (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (conv1_4)\n",
    "        conv1_4 = Dropout(0.5) (conv1_4)\n",
    "        \n",
    "        # X51 block\n",
    "        conv5_1 = Conv2D(nb_filter[4], (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (pool4_1)\n",
    "        conv5_1 = Dropout(0.5) (conv5_1)\n",
    "        conv5_1 = Conv2D(nb_filter[4], (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (conv5_1)\n",
    "        conv5_1 = Dropout(0.5) (conv5_1)\n",
    "        \n",
    "        # X42 block\n",
    "        up4_2 = Conv2DTranspose(nb_filter[3], (2, 2), strides=(2, 2), name='up42', padding='same')(conv5_1)\n",
    "        conv4_2 = concatenate([up4_2, conv4_1], name='merge42', axis=3) #x30\n",
    "        conv4_2 = Conv2D(nb_filter[3], (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (conv4_2)\n",
    "        conv4_2 = Dropout(0.5) (conv4_2)\n",
    "        conv4_2 = Conv2D(nb_filter[3], (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (conv4_2)\n",
    "        conv4_2 = Dropout(0.5) (conv4_2)\n",
    "        \n",
    "        # X33 block\n",
    "        up3_3 = Conv2DTranspose(nb_filter[2], (2, 2), strides=(2, 2), name='up33', padding='same')(conv4_2)\n",
    "        conv3_3 = concatenate([up3_3, conv3_1, conv3_2], name='merge33', axis=3)\n",
    "        conv3_3 = Conv2D(nb_filter[2], (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (conv3_3)\n",
    "        conv3_3 = Dropout(0.5) (conv3_3)\n",
    "        conv3_3 = Conv2D(nb_filter[2], (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (conv3_3)\n",
    "        conv3_3 = Dropout(0.5) (conv3_3)\n",
    "        \n",
    "        # X24 block\n",
    "        up2_4 = Conv2DTranspose(nb_filter[1], (2, 2), strides=(2, 2), name='up24', padding='same')(conv3_3)\n",
    "        conv2_4 = concatenate([up2_4, conv2_1, conv2_2, conv2_3], name='merge24', axis=3)\n",
    "        conv2_4 = Conv2D(nb_filter[1], (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (conv2_4)\n",
    "        conv2_4 = Dropout(0.5) (conv2_4)\n",
    "        conv2_4 = Conv2D(nb_filter[1], (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (conv2_4)\n",
    "        conv2_4 = Dropout(0.5) (conv2_4)\n",
    "        \n",
    "        # X15 block\n",
    "        up1_5 = Conv2DTranspose(nb_filter[0], (2, 2), strides=(2, 2), name='up15', padding='same')(conv2_4)\n",
    "        conv1_5 = concatenate([up1_5, conv1_1, conv1_2, conv1_3, conv1_4], name='merge15', axis=3)\n",
    "        conv1_5 = Conv2D(nb_filter[0], (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (conv1_5)\n",
    "        conv1_5 = Dropout(0.5) (conv1_5)\n",
    "        conv1_5 = Conv2D(nb_filter[0], (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (conv1_5)\n",
    "        conv1_5 = Dropout(0.5) (conv1_5)\n",
    "        \n",
    "#         u7 = UpSampling2D(size=2)(conv1_5) # upsamples to twice the size\n",
    "        output_img = Conv2D(channels, kernel_size=4, strides=1, padding='same', activation='tanh')(conv1_5)\n",
    "        \n",
    "#        nestnet_output_4 = Conv2D(1, (1, 1), activation='sigmoid', kernel_initializer = 'he_normal',  name='output_4', padding='same')(conv1_5)\n",
    "\n",
    "        return Model([inputs], [output_img])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bdbdfbf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_discriminator():\n",
    "        # a small function to make one layer of the discriminator\n",
    "        def d_layer(layer_input, filters, f_size=4, bn=True):\n",
    "            \"\"\"Discriminator layer\"\"\"\n",
    "            d = Conv2D(filters, kernel_size=f_size, strides=2, padding='same')(layer_input)\n",
    "            d = LeakyReLU(alpha=0.2)(d)\n",
    "            if bn:\n",
    "                d = BatchNormalization(momentum=0.8)(d)\n",
    "            return d\n",
    "\n",
    "        img_A = Input(shape=img_shape)\n",
    "        img_B = Input(shape=img_shape)\n",
    "\n",
    "        # Concatenate image and conditioning image by channels to produce input\n",
    "        combined_imgs = Concatenate(axis=-1)([img_A, img_B])\n",
    "\n",
    "        d1 = d_layer(combined_imgs, df, bn=False)\n",
    "        d2 = d_layer(d1, df*2)\n",
    "        d3 = d_layer(d2, df*4)\n",
    "        d4 = d_layer(d3, df*8)\n",
    "\n",
    "        validity = Conv2D(1, kernel_size=4, strides=1, padding='same')(d2)\n",
    "\n",
    "        return Model([img_A, img_B], validity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c36107f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input shape\n",
    "img_rows = 256\n",
    "img_cols = 256\n",
    "channels = 3\n",
    "img_shape = (img_rows, img_cols, channels)\n",
    "\n",
    "\n",
    "# Calculate output shape of D (PatchGAN)\n",
    "patch = int(img_rows / 2**2)\n",
    "disc_patch = (patch, patch, 1)\n",
    "\n",
    "# Number of filters in the first layer of G and D\n",
    "gf = 64\n",
    "df = 64\n",
    "\n",
    "optimizer = Adam(0.0002, 0.5)\n",
    "\n",
    "# Build and compile the discriminator\n",
    "discriminator = build_discriminator()\n",
    "discriminator.compile(loss='binary_crossentropy',\n",
    "            optimizer=optimizer,\n",
    "            metrics=['accuracy'])\n",
    "\n",
    "# Build the generator\n",
    "generator = build_generator()\n",
    "\n",
    "# Input images and their conditioning images\n",
    "img_A = Input(shape=img_shape)\n",
    "img_B = Input(shape=img_shape)\n",
    "\n",
    "# By conditioning on B generate a fake version of A\n",
    "fake_A = generator(img_B)\n",
    "\n",
    "# For the combined model we will only train the generator\n",
    "discriminator.trainable = False\n",
    "\n",
    "# Discriminators determines validity of translated images / condition pairs\n",
    "valid = discriminator([fake_A, img_B])\n",
    "\n",
    "def ssim_loss(valid, fake_A):\n",
    "    return 1 - tf.image.ssim(valid, fake_A, 1.0)\n",
    "    \n",
    "\n",
    "combined = Model(inputs=[img_A, img_B], outputs=[valid, fake_A])\n",
    "\n",
    "combined.compile(loss=['mse', 'mae'],\n",
    "                              loss_weights=[1, 100],\n",
    "                              optimizer=optimizer)\n",
    "\n",
    "# combined.compile(loss=[ssim_loss], optimizer=optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "638cedf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_images( epoch, batch_i):\n",
    "        \n",
    "        r, c = 3, 3\n",
    "\n",
    "        imgs_A, imgs_B = load_data(batch_size=3)\n",
    "        fake_A = generator.predict(imgs_B)\n",
    "\n",
    "        gen_imgs = np.concatenate([imgs_B, fake_A, imgs_A])\n",
    "\n",
    "        # Rescale images 0 - 1\n",
    "        gen_imgs = 0.5 * gen_imgs + 0.5\n",
    "\n",
    "        titles = ['Input', 'Output', 'Ground Truth']\n",
    "        fig, axs = plt.subplots(r, c)\n",
    "        cnt = 0\n",
    "        for i in range(r):\n",
    "            for j in range(c):\n",
    "                axs[i,j].imshow(gen_imgs[cnt])\n",
    "                axs[i, j].set_title(titles[i])\n",
    "                axs[i,j].axis('off')\n",
    "                cnt += 1\n",
    "        plt.show()\n",
    "        plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "35c7c25e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train( epochs, batch_size=1, show_interval=10):\n",
    "\n",
    "        start_time = datetime.datetime.now()\n",
    "\n",
    "        # Adversarial loss ground truths\n",
    "        valid = np.ones((batch_size,) + disc_patch)\n",
    "        fake = np.zeros((batch_size,) + disc_patch)\n",
    "\n",
    "        for epoch in range(epochs):\n",
    "            for batch_i, (imgs_A, imgs_B) in enumerate(load_batch(batch_size)):\n",
    "\n",
    "                \n",
    "                #  Train Discriminator\n",
    "                \n",
    "\n",
    "                # Condition on B and generate a translated version\n",
    "                fake_A = generator.predict(imgs_B)\n",
    "                \n",
    "                # Train the discriminators (original images = real / generated = Fake)\n",
    "                d_loss_real = discriminator.train_on_batch([imgs_A, imgs_B], valid)\n",
    "                d_loss_fake = discriminator.train_on_batch([fake_A, imgs_B], fake)\n",
    "                d_loss = 0.5 * np.add(d_loss_real, d_loss_fake)\n",
    "\n",
    "               \n",
    "                #  Train Generator\n",
    "                g_loss = combined.train_on_batch([imgs_A, imgs_B], [valid, imgs_A])\n",
    "\n",
    "                elapsed_time = datetime.datetime.now() - start_time\n",
    "                \n",
    "            # Plot the progress\n",
    "            if epoch%10==0:\n",
    "                  print (\"[Epoch %d/%d]  [D loss: %f, acc: %3d%%] [G loss: %f] time: %s\" % (epoch, epochs,\n",
    "                                                                        \n",
    "                                                                        d_loss[0], 100*d_loss[1],\n",
    "                                                                        g_loss[0],\n",
    "                                                                        elapsed_time))\n",
    "            # If at show interval => show generated image samples\n",
    "            if epoch % show_interval == 0:\n",
    "                    show_images(epoch, batch_i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b82518f6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tf' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43mtf\u001b[49m\u001b[38;5;241m.\u001b[39mdevice(tf\u001b[38;5;241m.\u001b[39mDeviceSpec(device_type\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGPU\u001b[39m\u001b[38;5;124m\"\u001b[39m, device_index\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)):\n\u001b[0;32m      2\u001b[0m     train(epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m6000\u001b[39m, batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m4\u001b[39m, show_interval\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'tf' is not defined"
     ]
    }
   ],
   "source": [
    "with tf.device(tf.DeviceSpec(device_type=\"GPU\", device_index=0)):\n",
    "    train(epochs=6000, batch_size=4, show_interval=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "98a16cde",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('temp4.pkl', 'wb') as file:\n",
    "        pickle.dump(generator, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c44e132",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "665dcac5",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('temp.pkl', 'rb') as file:\n",
    "        generator1 = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5db237a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_images_1( epoch, batch_i, generator1):\n",
    "        \n",
    "        r, c = 3, 3\n",
    "\n",
    "        imgs_A, imgs_B = load_data(batch_size=3)\n",
    "        fake_A = generator1.predict(imgs_B)\n",
    "\n",
    "        gen_imgs = np.concatenate([imgs_B, fake_A, imgs_A])\n",
    "\n",
    "        # Rescale images 0 - 1\n",
    "        gen_imgs = 0.5 * gen_imgs + 0.5\n",
    "\n",
    "        titles = ['Input', 'Output', 'Ground Truth']\n",
    "        fig, axs = plt.subplots(r, c)\n",
    "        cnt = 0\n",
    "        for i in range(r):\n",
    "            for j in range(c):\n",
    "                axs[i,j].imshow(gen_imgs[cnt])\n",
    "                axs[i, j].set_title(titles[i])\n",
    "                axs[i,j].axis('off')\n",
    "                cnt += 1\n",
    "        plt.show()\n",
    "        plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bd2e43b",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_images_1(1,1,1,generator1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fcf1036",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
