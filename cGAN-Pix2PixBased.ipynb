{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c43c56be",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import scipy\n",
    "from glob import glob\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage import transform\n",
    "from __future__ import print_function, division\n",
    "import tensorflow as tf\n",
    "from keras.layers import Input, Dense, Reshape, Flatten, Dropout, Concatenate\n",
    "from keras.layers import BatchNormalization, Activation, ZeroPadding2D\n",
    "from keras.layers import LeakyReLU\n",
    "from keras.layers.convolutional import UpSampling2D, Conv2D\n",
    "from keras.models import Sequential, Model\n",
    "from keras.optimizers import Adam\n",
    "import datetime\n",
    "import sys\n",
    "import os\n",
    "from imageio import imread\n",
    "from PIL import Image\n",
    "import pickle\n",
    "from skimage.metrics import structural_similarity as ssim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f5cc74db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# config for GPU usage.\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "\n",
    "config = tf.compat.v1.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "sess = tf.compat.v1.Session(config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "dbc29bed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(batch_size=1, is_val = False):\n",
    "       ''' function to load a battch of images specified by batch size'''\n",
    "        \n",
    "        path_SAR = glob('Datasets/v_2/agri/s1/*')\n",
    "        \n",
    "        # \n",
    "        batch_images = np.random.choice(path_SAR, size=batch_size)\n",
    "        img_res=(256,256)\n",
    "        imgs_A = []\n",
    "        imgs_B = []\n",
    "        for img_path in batch_images:\n",
    "            img_B = imread(img_path)\n",
    "            img_A = imread(img_path.replace('/s1', '/s2').replace(\"_s1_\",\"_s2_\"))\n",
    "    \n",
    "            # decreasing the resolution \n",
    "            img_A = transform.resize(img_A, img_res)  #RGB image\n",
    "            img_B = transform.resize(img_B, img_res)  #SAR image\n",
    "\n",
    "            # If training => do random flip , this is a trick to avoid overfitting \n",
    "            if not is_val and np.random.random() < 0.5:\n",
    "                img_A = np.fliplr(img_A)\n",
    "                img_B = np.fliplr(img_B)\n",
    "\n",
    "            imgs_A.append(img_A)\n",
    "            imgs_B.append(img_B)\n",
    "            \n",
    "        \n",
    "        imgs_A = np.array(imgs_A)/127.5 - 1.  #normalizing the images\n",
    "        imgs_B = np.array(imgs_B)/127.5 - 1.\n",
    "\n",
    "        return imgs_A, imgs_B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8292c66b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_batch(batch_size=1, is_val=False):\n",
    "        \n",
    "        path_SAR = glob('Datasets/v_2/agri/s1/*')\n",
    "        \n",
    "        n_batches=batch_size\n",
    "        img_res=(256,256)\n",
    "        for i in range(n_batches-1):\n",
    "            batch = path_SAR[i*batch_size:(i+1)*batch_size]\n",
    "            imgs_A, imgs_B = [], []\n",
    "            for img in batch:\n",
    "                img_B = imread(img)\n",
    "                img_A = imread(img.replace('/s1', '/s2').replace(\"_s1_\",\"_s2_\"))\n",
    "                \n",
    "                img_A = transform.resize(img_A, img_res)# RGB image\n",
    "                img_B = transform.resize(img_B, img_res)# SAR image\n",
    "                \n",
    "                 # when training => do random flip , this is a trick to avoid overfitting \n",
    "                if not is_val and np.random.random() > 0.5:\n",
    "                        img_A = np.fliplr(img_A)\n",
    "                        img_B = np.fliplr(img_B)\n",
    "                \n",
    "                imgs_A.append(img_A)\n",
    "                imgs_B.append(img_B)\n",
    "                \n",
    "            # normalizing the images \n",
    "            imgs_A = np.array(imgs_A)/127.5 - 1.\n",
    "            imgs_B = np.array(imgs_B)/127.5 - 1.\n",
    "\n",
    "            yield imgs_A, imgs_B\n",
    "\n",
    "            \n",
    "def imread(path):\n",
    "    '''function that reads an image and converts it into float32 type'''\n",
    "    return np.array(Image.open(path).convert('RGB')).astype(np.float32)\n",
    "                            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9b77f671",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from PIL import Image\n",
    "\n",
    "# path_SAR = glob('Datasets/v_2/agri/s1/*')\n",
    "\n",
    "\n",
    "# # Open an image file\n",
    "# image = Image.open(path_SAR[1].replace('/s1', '/s2').replace(\"_s1_\",\"_s2_\"))\n",
    "\n",
    "# # Display the image\n",
    "# image.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "2118688f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_generator():\n",
    "        \"\"\"U-Net Generator\"\"\"\n",
    "\n",
    "        def conv2d(layer_input, filters, f_size=4, bn=True):\n",
    "            \"\"\"Layers used during downsampling\"\"\"\n",
    "            d = Conv2D(filters, kernel_size=f_size, strides=2, padding='same')(layer_input)\n",
    "            d = LeakyReLU(alpha=0.2)(d)\n",
    "            if bn:\n",
    "                d = BatchNormalization(momentum=0.8)(d)\n",
    "            return d\n",
    "\n",
    "        def deconv2d(layer_input, skip_input, filters, f_size=4, dropout_rate=0):\n",
    "            \"\"\"Layers used during upsampling\"\"\"\n",
    "            u = UpSampling2D(size=2)(layer_input)\n",
    "            u = Conv2D(filters, kernel_size=f_size, strides=1, padding='same', activation='relu')(u)\n",
    "            if dropout_rate:\n",
    "                u = Dropout(dropout_rate)(u)\n",
    "            u = BatchNormalization(momentum=0.8)(u)\n",
    "            u = Concatenate()([u, skip_input]) #skip connection\n",
    "            return u\n",
    "        \n",
    "        d0 = Input(shape=img_shape)\n",
    "\n",
    "        # Downsampling\n",
    "        d1 = conv2d(d0, gf, bn=False)\n",
    "        d2 = conv2d(d1, gf*2)\n",
    "        d3 = conv2d(d2, gf*4)\n",
    "        d4 = conv2d(d3, gf*8)\n",
    "        d5 = conv2d(d4, gf*8)\n",
    "        d6 = conv2d(d5, gf*8)\n",
    "        d7 = conv2d(d6, gf*8)\n",
    "\n",
    "        # Upsampling\n",
    "        u1 = deconv2d(d7, d6, gf*8)\n",
    "        u2 = deconv2d(u1, d5, gf*8)\n",
    "        u3 = deconv2d(u2, d4, gf*8)\n",
    "        u4 = deconv2d(u3, d3, gf*4)\n",
    "        u5 = deconv2d(u4, d2, gf*2)\n",
    "        u6 = deconv2d(u5, d1, gf)\n",
    "        \n",
    "        u7 = UpSampling2D(size=2)(u6)\n",
    "        output_img = Conv2D(channels, kernel_size=4, strides=1, padding='same', activation='tanh')(u7)\n",
    "\n",
    "        return Model(d0, output_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "bdbdfbf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_discriminator():\n",
    "        # a small function to make one layer of the discriminator\n",
    "        def d_layer(layer_input, filters, f_size=4, bn=True):\n",
    "            \"\"\"Discriminator layer\"\"\"\n",
    "            d = Conv2D(filters, kernel_size=f_size, strides=2, padding='same')(layer_input)\n",
    "            d = LeakyReLU(alpha=0.2)(d)\n",
    "            if bn:\n",
    "                d = BatchNormalization(momentum=0.8)(d)\n",
    "            return d\n",
    "\n",
    "        img_A = Input(shape=img_shape)\n",
    "        img_B = Input(shape=img_shape)\n",
    "\n",
    "        # Concatenate image and conditioning image by channels to produce input\n",
    "        combined_imgs = Concatenate(axis=-1)([img_A, img_B])\n",
    "\n",
    "        d1 = d_layer(combined_imgs, df, bn=False)\n",
    "        d2 = d_layer(d1, df*2)\n",
    "        d3 = d_layer(d2, df*4)\n",
    "        d4 = d_layer(d3, df*8)\n",
    "\n",
    "        validity = Conv2D(1, kernel_size=4, strides=1, padding='same')(d2)\n",
    "\n",
    "        return Model([img_A, img_B], validity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c36107f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input shape\n",
    "img_rows = 256\n",
    "img_cols = 256\n",
    "channels = 3\n",
    "img_shape = (img_rows, img_cols, channels)\n",
    "\n",
    "\n",
    "# Calculate output shape of D (PatchGAN)\n",
    "patch = int(img_rows / 2**2)\n",
    "disc_patch = (patch, patch, 1)\n",
    "\n",
    "# Number of filters in the first layer of G and D\n",
    "gf = 64\n",
    "df = 64\n",
    "\n",
    "optimizer = Adam(0.0002, 0.5)\n",
    "\n",
    "# Build and compile the discriminator\n",
    "discriminator = build_discriminator()\n",
    "discriminator.compile(loss='binary_crossentropy',\n",
    "            optimizer=optimizer,\n",
    "            metrics=['accuracy'])\n",
    "\n",
    "# Build the generator\n",
    "generator = build_generator()\n",
    "\n",
    "# Input images and their conditioning images\n",
    "img_A = Input(shape=img_shape)\n",
    "img_B = Input(shape=img_shape)\n",
    "\n",
    "# By conditioning on B generate a fake version of A\n",
    "fake_A = generator(img_B)\n",
    "\n",
    "# For the combined model we will only train the generator\n",
    "discriminator.trainable = False\n",
    "\n",
    "# Discriminators determines validity of translated images / condition pairs\n",
    "valid = discriminator([fake_A, img_B])\n",
    "\n",
    "\n",
    "def ssim_loss(valid, fake_A):\n",
    "    '''function calculates ssim loss, flips and converts it into 0-1 range'''\n",
    "    return 1- tf.image.ssim(valid, fake_A, 1.0)\n",
    "    \n",
    "\n",
    "combined = Model(inputs=[img_A, img_B], outputs=[valid, fake_A])\n",
    "\n",
    "# combined.compile(loss=['mse', 'mae'],\n",
    "#                               loss_weights=[1, 100],\n",
    "#                               optimizer=optimizer)\n",
    "\n",
    "combined.compile(loss=['mse', ssim_loss], loss_weights=[50, 50], optimizer=optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "638cedf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_images( epoch, batch_i):\n",
    "        '''function to take 3 images and show the results'''\n",
    "        r, c = 3, 3\n",
    "\n",
    "        imgs_A, imgs_B = load_data(batch_size=3)\n",
    "        fake_A = generator.predict(imgs_B)\n",
    "\n",
    "        gen_imgs = np.concatenate([imgs_B, fake_A, imgs_A])\n",
    "\n",
    "        # Rescale images 0 - 1\n",
    "        gen_imgs = 0.5 * gen_imgs + 0.5\n",
    "\n",
    "        titles = ['Input', 'Output', 'Ground Truth']\n",
    "        fig, axs = plt.subplots(r, c)\n",
    "        cnt = 0\n",
    "        for i in range(r):\n",
    "            for j in range(c):\n",
    "                axs[i,j].imshow(gen_imgs[cnt])\n",
    "                axs[i, j].set_title(titles[i])\n",
    "                axs[i,j].axis('off')\n",
    "                cnt += 1\n",
    "        plt.show()\n",
    "        plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "35c7c25e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train( epochs, batch_size=1, show_interval=10):\n",
    "\n",
    "        start_time = datetime.datetime.now()\n",
    "\n",
    "        # Adversarial loss ground truths\n",
    "        valid = np.ones((batch_size,) + disc_patch)\n",
    "        fake = np.zeros((batch_size,) + disc_patch)\n",
    "\n",
    "        for epoch in range(epochs):\n",
    "            for batch_i, (imgs_A, imgs_B) in enumerate(load_batch(batch_size)):\n",
    "\n",
    "                \n",
    "                #  Train Discriminator\n",
    "\n",
    "                # Condition on B and generate a translated version\n",
    "                fake_A = generator.predict(imgs_B)\n",
    "                \n",
    "                # Train the discriminators (original images = real / generated = Fake)\n",
    "                d_loss_real = discriminator.train_on_batch([imgs_A, imgs_B], valid)\n",
    "                d_loss_fake = discriminator.train_on_batch([fake_A, imgs_B], fake)\n",
    "                d_loss = 0.5 * np.add(d_loss_real, d_loss_fake)\n",
    "\n",
    "               \n",
    "                #  Train Generator\n",
    "                g_loss = combined.train_on_batch([imgs_A, imgs_B], [valid, imgs_A])\n",
    "\n",
    "                elapsed_time = datetime.datetime.now() - start_time\n",
    "                \n",
    "            # Plot the progress\n",
    "            if epoch%10==0:\n",
    "                  print (\"[Epoch %d/%d]  [D loss: %f, acc: %3d%%] [G loss: %f] time: %s\" % (epoch, epochs,\n",
    "                                                                        \n",
    "                                                                        d_loss[0], 100*d_loss[1],\n",
    "                                                                        g_loss[0],\n",
    "                                                                        elapsed_time))\n",
    "            # If at show interval => show generated image samples\n",
    "            if epoch % show_interval == 0:\n",
    "                    show_images(epoch, batch_i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b82518f6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 417ms/step\n"
     ]
    },
    {
     "ename": "ResourceExhaustedError",
     "evalue": "Graph execution error:\n\nDetected at node 'model_14/model_13/conv2d_94/Conv2D' defined at (most recent call last):\n    File \"C:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python310\\lib\\runpy.py\", line 196, in _run_module_as_main\n      return _run_code(code, main_globals, None,\n    File \"C:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python310\\lib\\runpy.py\", line 86, in _run_code\n      exec(code, run_globals)\n    File \"C:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\ipykernel_launcher.py\", line 17, in <module>\n      app.launch_new_instance()\n    File \"C:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\traitlets\\config\\application.py\", line 1043, in launch_instance\n      app.start()\n    File \"C:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 725, in start\n      self.io_loop.start()\n    File \"C:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 195, in start\n      self.asyncio_loop.run_forever()\n    File \"C:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python310\\lib\\asyncio\\base_events.py\", line 603, in run_forever\n      self._run_once()\n    File \"C:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python310\\lib\\asyncio\\base_events.py\", line 1909, in _run_once\n      handle._run()\n    File \"C:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python310\\lib\\asyncio\\events.py\", line 80, in _run\n      self._context.run(self._callback, *self._args)\n    File \"C:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 513, in dispatch_queue\n      await self.process_one()\n    File \"C:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 502, in process_one\n      await dispatch(*args)\n    File \"C:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 409, in dispatch_shell\n      await result\n    File \"C:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 729, in execute_request\n      reply_content = await reply_content\n    File \"C:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 422, in do_execute\n      res = shell.run_cell(\n    File \"C:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 540, in run_cell\n      return super().run_cell(*args, **kwargs)\n    File \"C:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3009, in run_cell\n      result = self._run_cell(\n    File \"C:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3064, in _run_cell\n      result = runner(coro)\n    File \"C:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 129, in _pseudo_sync_runner\n      coro.send(None)\n    File \"C:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3269, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"C:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3448, in run_ast_nodes\n      if await self.run_code(code, result, async_=asy):\n    File \"C:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3508, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_20296\\1492172869.py\", line 2, in <module>\n      train(epochs=1000, batch_size=4, show_interval=10)\n    File \"C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_20296\\2030940563.py\", line 25, in train\n      g_loss = combined.train_on_batch([imgs_A, imgs_B], [valid, imgs_A])\n    File \"C:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\engine\\training.py\", line 2381, in train_on_batch\n      logs = self.train_function(iterator)\n    File \"C:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\engine\\training.py\", line 1160, in train_function\n      return step_function(self, iterator)\n    File \"C:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\engine\\training.py\", line 1146, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"C:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\engine\\training.py\", line 1135, in run_step\n      outputs = model.train_step(data)\n    File \"C:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\engine\\training.py\", line 993, in train_step\n      y_pred = self(x, training=True)\n    File \"C:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\engine\\training.py\", line 557, in __call__\n      return super().__call__(*args, **kwargs)\n    File \"C:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\engine\\base_layer.py\", line 1097, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"C:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\engine\\functional.py\", line 510, in call\n      return self._run_internal_graph(inputs, training=training, mask=mask)\n    File \"C:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\engine\\functional.py\", line 667, in _run_internal_graph\n      outputs = node.layer(*args, **kwargs)\n    File \"C:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\engine\\training.py\", line 557, in __call__\n      return super().__call__(*args, **kwargs)\n    File \"C:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\engine\\base_layer.py\", line 1097, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"C:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\engine\\functional.py\", line 510, in call\n      return self._run_internal_graph(inputs, training=training, mask=mask)\n    File \"C:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\engine\\functional.py\", line 667, in _run_internal_graph\n      outputs = node.layer(*args, **kwargs)\n    File \"C:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\engine\\base_layer.py\", line 1097, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"C:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\layers\\convolutional\\base_conv.py\", line 283, in call\n      outputs = self.convolution_op(inputs, self.kernel)\n    File \"C:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\layers\\convolutional\\base_conv.py\", line 255, in convolution_op\n      return tf.nn.convolution(\nNode: 'model_14/model_13/conv2d_94/Conv2D'\nOOM when allocating tensor with shape[4,257,257,128] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[{{node model_14/model_13/conv2d_94/Conv2D}}]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.\n [Op:__inference_train_function_18279]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[35], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mdevice(tf\u001b[38;5;241m.\u001b[39mDeviceSpec(device_type\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGPU\u001b[39m\u001b[38;5;124m\"\u001b[39m, device_index\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)):\n\u001b[1;32m----> 2\u001b[0m     \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1000\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m4\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshow_interval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[34], line 25\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(epochs, batch_size, show_interval)\u001b[0m\n\u001b[0;32m     21\u001b[0m     d_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.5\u001b[39m \u001b[38;5;241m*\u001b[39m np\u001b[38;5;241m.\u001b[39madd(d_loss_real, d_loss_fake)\n\u001b[0;32m     24\u001b[0m     \u001b[38;5;66;03m#  Train Generator\u001b[39;00m\n\u001b[1;32m---> 25\u001b[0m     g_loss \u001b[38;5;241m=\u001b[39m \u001b[43mcombined\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_on_batch\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mimgs_A\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mimgs_B\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43mvalid\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mimgs_A\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     27\u001b[0m     elapsed_time \u001b[38;5;241m=\u001b[39m datetime\u001b[38;5;241m.\u001b[39mdatetime\u001b[38;5;241m.\u001b[39mnow() \u001b[38;5;241m-\u001b[39m start_time\n\u001b[0;32m     29\u001b[0m \u001b[38;5;66;03m# Plot the progress\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\engine\\training.py:2381\u001b[0m, in \u001b[0;36mModel.train_on_batch\u001b[1;34m(self, x, y, sample_weight, class_weight, reset_metrics, return_dict)\u001b[0m\n\u001b[0;32m   2377\u001b[0m     iterator \u001b[38;5;241m=\u001b[39m data_adapter\u001b[38;5;241m.\u001b[39msingle_batch_iterator(\n\u001b[0;32m   2378\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdistribute_strategy, x, y, sample_weight, class_weight\n\u001b[0;32m   2379\u001b[0m     )\n\u001b[0;32m   2380\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrain_function \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmake_train_function()\n\u001b[1;32m-> 2381\u001b[0m     logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2383\u001b[0m logs \u001b[38;5;241m=\u001b[39m tf_utils\u001b[38;5;241m.\u001b[39msync_to_numpy_or_python_type(logs)\n\u001b[0;32m   2384\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m return_dict:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:153\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m--> 153\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    154\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    155\u001b[0m   \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:54\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 54\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m pywrap_tfe\u001b[38;5;241m.\u001b[39mTFE_Py_Execute(ctx\u001b[38;5;241m.\u001b[39m_handle, device_name, op_name,\n\u001b[0;32m     55\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[0;32m     56\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     57\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mResourceExhaustedError\u001b[0m: Graph execution error:\n\nDetected at node 'model_14/model_13/conv2d_94/Conv2D' defined at (most recent call last):\n    File \"C:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python310\\lib\\runpy.py\", line 196, in _run_module_as_main\n      return _run_code(code, main_globals, None,\n    File \"C:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python310\\lib\\runpy.py\", line 86, in _run_code\n      exec(code, run_globals)\n    File \"C:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\ipykernel_launcher.py\", line 17, in <module>\n      app.launch_new_instance()\n    File \"C:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\traitlets\\config\\application.py\", line 1043, in launch_instance\n      app.start()\n    File \"C:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 725, in start\n      self.io_loop.start()\n    File \"C:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 195, in start\n      self.asyncio_loop.run_forever()\n    File \"C:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python310\\lib\\asyncio\\base_events.py\", line 603, in run_forever\n      self._run_once()\n    File \"C:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python310\\lib\\asyncio\\base_events.py\", line 1909, in _run_once\n      handle._run()\n    File \"C:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python310\\lib\\asyncio\\events.py\", line 80, in _run\n      self._context.run(self._callback, *self._args)\n    File \"C:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 513, in dispatch_queue\n      await self.process_one()\n    File \"C:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 502, in process_one\n      await dispatch(*args)\n    File \"C:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 409, in dispatch_shell\n      await result\n    File \"C:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 729, in execute_request\n      reply_content = await reply_content\n    File \"C:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 422, in do_execute\n      res = shell.run_cell(\n    File \"C:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 540, in run_cell\n      return super().run_cell(*args, **kwargs)\n    File \"C:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3009, in run_cell\n      result = self._run_cell(\n    File \"C:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3064, in _run_cell\n      result = runner(coro)\n    File \"C:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 129, in _pseudo_sync_runner\n      coro.send(None)\n    File \"C:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3269, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"C:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3448, in run_ast_nodes\n      if await self.run_code(code, result, async_=asy):\n    File \"C:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3508, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_20296\\1492172869.py\", line 2, in <module>\n      train(epochs=1000, batch_size=4, show_interval=10)\n    File \"C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_20296\\2030940563.py\", line 25, in train\n      g_loss = combined.train_on_batch([imgs_A, imgs_B], [valid, imgs_A])\n    File \"C:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\engine\\training.py\", line 2381, in train_on_batch\n      logs = self.train_function(iterator)\n    File \"C:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\engine\\training.py\", line 1160, in train_function\n      return step_function(self, iterator)\n    File \"C:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\engine\\training.py\", line 1146, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"C:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\engine\\training.py\", line 1135, in run_step\n      outputs = model.train_step(data)\n    File \"C:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\engine\\training.py\", line 993, in train_step\n      y_pred = self(x, training=True)\n    File \"C:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\engine\\training.py\", line 557, in __call__\n      return super().__call__(*args, **kwargs)\n    File \"C:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\engine\\base_layer.py\", line 1097, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"C:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\engine\\functional.py\", line 510, in call\n      return self._run_internal_graph(inputs, training=training, mask=mask)\n    File \"C:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\engine\\functional.py\", line 667, in _run_internal_graph\n      outputs = node.layer(*args, **kwargs)\n    File \"C:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\engine\\training.py\", line 557, in __call__\n      return super().__call__(*args, **kwargs)\n    File \"C:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\engine\\base_layer.py\", line 1097, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"C:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\engine\\functional.py\", line 510, in call\n      return self._run_internal_graph(inputs, training=training, mask=mask)\n    File \"C:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\engine\\functional.py\", line 667, in _run_internal_graph\n      outputs = node.layer(*args, **kwargs)\n    File \"C:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\engine\\base_layer.py\", line 1097, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"C:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\layers\\convolutional\\base_conv.py\", line 283, in call\n      outputs = self.convolution_op(inputs, self.kernel)\n    File \"C:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\layers\\convolutional\\base_conv.py\", line 255, in convolution_op\n      return tf.nn.convolution(\nNode: 'model_14/model_13/conv2d_94/Conv2D'\nOOM when allocating tensor with shape[4,257,257,128] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[{{node model_14/model_13/conv2d_94/Conv2D}}]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.\n [Op:__inference_train_function_18279]"
     ]
    }
   ],
   "source": [
    "# training the model\n",
    "\n",
    "with tf.device(tf.DeviceSpec(device_type=\"GPU\", device_index=0)):\n",
    "    train(epochs=1000, batch_size=4, show_interval=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f146d58e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98a16cde",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('temp.pkl', 'wb') as file:\n",
    "        pickle.dump(generator, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c44e132",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "665dcac5",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('temp.pkl', 'rb') as file:\n",
    "        generator1 = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5db237a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_images_1( epoch, batch_i, generator1):\n",
    "        \n",
    "        r, c = 3, 3\n",
    "\n",
    "        imgs_A, imgs_B = load_data(batch_size=3)\n",
    "        fake_A = generator1.predict(imgs_B)\n",
    "\n",
    "        gen_imgs = np.concatenate([imgs_B, fake_A, imgs_A])\n",
    "\n",
    "        # Rescale images 0 - 1\n",
    "        gen_imgs = 0.5 * gen_imgs + 0.5\n",
    "\n",
    "        titles = ['Input', 'Output', 'Ground Truth']\n",
    "        fig, axs = plt.subplots(r, c)\n",
    "        cnt = 0\n",
    "        for i in range(r):\n",
    "            for j in range(c):\n",
    "                axs[i,j].imshow(gen_imgs[cnt])\n",
    "                axs[i, j].set_title(titles[i])\n",
    "                axs[i,j].axis('off')\n",
    "                cnt += 1\n",
    "        plt.show()\n",
    "        plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bd2e43b",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_images_1(1,1,1,generator1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fcf1036",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
